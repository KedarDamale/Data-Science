{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9d843330",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff829760",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "What is Deep Learning?\n",
    "\n",
    "Deep Learning is a subset of Machine Learning (ML), which itself is a subset of Artificial Intelligence (AI).\n",
    "    AI = making machines smart enough to do tasks that typically require human intelligence.\n",
    "    ML = making machines learn from data and improve over time without explicit programming for each task.\n",
    "    Deep Learning (DL) = a specialized branch of ML that uses artificial neural networks with many layers (hence \"deep\") to model and solve complex problems.\n",
    "\n",
    "The term \"deep\" refers to the number of layers in the neural network. Traditional ML models are often shallow (few layers), but deep learning models have:\n",
    "    Multiple hidden layers between input and output layers.\n",
    "    These layers enable the model to learn hierarchical representations of data ‚Äî from simple features in early layers to complex features in later layers.\n",
    "\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e0a6eca0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\n+----------------------------+------------------------------------------------------+---------------------------------------------------------+\\n|         Feature           |                  Machine Learning (ML)              |                  Deep Learning (DL)                     |\\n+----------------------------+------------------------------------------------------+---------------------------------------------------------+\\n| Definition                 | Subset of AI where algorithms learn from data.       | Subset of ML that uses multi-layered neural networks.    |\\n| Data Dependency            | Works well with smaller datasets.                    | Requires large amounts of data to perform well.          |\\n| Feature Engineering        | Manual ‚Äî features must be selected and created.      | Automatic ‚Äî extracts features via neural layers.         |\\n| Execution Time            | Generally faster for small/medium datasets.          | Slower due to complex architectures and high computation.|\\n| Interpretability           | More interpretable (e.g., decision trees, SVM).      | Less interpretable (black-box models).                   |\\n| Hardware Dependency        | Can run on CPU easily.                               | Requires high-end GPU/TPU for training efficiency.       |\\n| Accuracy with Big Data     | Plateaus or improves marginally.                     | Accuracy improves significantly with more data.          |\\n| Examples of Algorithms     | Linear Regression, SVM, Decision Trees, KNN.         | CNN, RNN, LSTM, GAN, Transformers.                       |\\n| Use Cases                  | Fraud detection, recommendation systems, spam filter| Image recognition, speech-to-text, NLP tasks.            |\\n| Architecture               | Simple models, shallow structures.                  | Deep Neural Networks (many layers).                      |\\n| Learning Approach          | Supervised/semi-supervised/unsupervised             | Mostly supervised (some unsupervised like autoencoders). |\\n| Model Size                 | Relatively small models.                             | Large models with millions of parameters.                |\\n| Training Time              | Shorter training time.                               | Requires longer training time.                           |\\n| Scalability                | Harder to scale on large datasets.                   | Easily scales with data and computing power.             |\\n| Performance on Unstructured Data | Limited (needs preprocessing).               | Excellent (especially for images, audio, text).          |\\n+----------------------------+------------------------------------------------------+---------------------------------------------------------+\\n\\n'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "+----------------------------+------------------------------------------------------+---------------------------------------------------------+\n",
    "|         Feature           |                  Machine Learning (ML)              |                  Deep Learning (DL)                     |\n",
    "+----------------------------+------------------------------------------------------+---------------------------------------------------------+\n",
    "| Definition                 | Subset of AI where algorithms learn from data.       | Subset of ML that uses multi-layered neural networks.    |\n",
    "| Data Dependency            | Works well with smaller datasets.                    | Requires large amounts of data to perform well.          |\n",
    "| Feature Engineering        | Manual ‚Äî features must be selected and created.      | Automatic ‚Äî extracts features via neural layers.         |\n",
    "| Execution Time            | Generally faster for small/medium datasets.          | Slower due to complex architectures and high computation.|\n",
    "| Interpretability           | More interpretable (e.g., decision trees, SVM).      | Less interpretable (black-box models).                   |\n",
    "| Hardware Dependency        | Can run on CPU easily.                               | Requires high-end GPU/TPU for training efficiency.       |\n",
    "| Accuracy with Big Data     | Plateaus or improves marginally.                     | Accuracy improves significantly with more data.          |\n",
    "| Examples of Algorithms     | Linear Regression, SVM, Decision Trees, KNN.         | CNN, RNN, LSTM, GAN, Transformers.                       |\n",
    "| Use Cases                  | Fraud detection, recommendation systems, spam filter| Image recognition, speech-to-text, NLP tasks.            |\n",
    "| Architecture               | Simple models, shallow structures.                  | Deep Neural Networks (many layers).                      |\n",
    "| Learning Approach          | Supervised/semi-supervised/unsupervised             | Mostly supervised (some unsupervised like autoencoders). |\n",
    "| Model Size                 | Relatively small models.                             | Large models with millions of parameters.                |\n",
    "| Training Time              | Shorter training time.                               | Requires longer training time.                           |\n",
    "| Scalability                | Harder to scale on large datasets.                   | Easily scales with data and computing power.             |\n",
    "| Performance on Unstructured Data | Limited (needs preprocessing).               | Excellent (especially for images, audio, text).          |\n",
    "+----------------------------+------------------------------------------------------+---------------------------------------------------------+\n",
    "\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56d2e57c",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Artificial neurons and artificial neural networks\n",
    "\n",
    "Neurons are fundamental units of the brain and nervous system that are responsible \n",
    "for receiving, processing, and transmitting information via electrical and chemical signals.\n",
    "\n",
    "They are specialized cells found in both biological systems (like human brains) and artificial\n",
    "systems (like neural networks in machine learning), although the two are conceptually inspired\n",
    "but structurally very different.\n",
    "\n",
    "How It Works (Signal Flow): Signal Reception: Dendrites receive chemical/electrical signals from other neurons.\n",
    "                            Processing: Signals are summed in the cell body. If the total input exceeds a threshold, the neuron fires.\n",
    "                            Signal Transmission: An action potential is generated and travels down the axon.\n",
    "                            Synaptic Transmission: Neurotransmitters are released into the synaptic cleft and bind to receptors on the next neuron.\n",
    "                            This process is known as synaptic communication.\n",
    "\n",
    "Inspired by biological neurons, artificial neurons (used in artificial neural networks)\n",
    "are mathematical functions that compute weighted sums and apply activation functions like ReLU, Sigmoid, Tanh, etc.\n",
    "\n",
    "An artificial neuron takes multiple inputs, applies weights, adds a bias, \n",
    "and passes the result through an activation function\n",
    "E.g. Output = Activation( w1*x1 + w2*x2 + ... + wn*xn + b )\n",
    "\n",
    "\n",
    "\n",
    "Major types of Deep learning network:1.Perceptron\n",
    "                                     2.multi layered perceptron (ANN)\n",
    "                                     3.convolutional neural network \n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52a82b07",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Perceptron explanation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9bee5773",
   "metadata": {},
   "source": [
    "![Alt text](7.images\\perceptron.png)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5b47a24",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "A Perceptron is the simplest type of artificial neural network,\n",
    "and is used for binary classification. It was invented by Frank Rosenblatt in 1958.\n",
    "\n",
    "It mimics a single biological neuron.\n",
    "\n",
    "Structure of a Perceptron:\n",
    "\n",
    "1.Inputs means each column so x1=CGPA and x2=SGPA\n",
    "2. w means weight whihc each inmput will have (weight is a learnable parameter that determines how much influence an input feature has on the final output.)\n",
    "3.bias :the bias is a learnable constant that allows the model to shift the decision boundary.(a decision boundary is the surface (line, curve, plane, or hyperplane) \n",
    "                                                                                               that separates different classes in the feature space based on the learned model.)\n",
    "\n",
    "4.Summation Function: computes weighted sum (summation of dot product of inputs and weights) and adds bias to the summation\n",
    "5.Activation function: An activation function is a mathematical operation applied to the output of a neuron (z) to decide whether it should be activated (fired) or not.\n",
    "  summation function is passed through activation function to get the output i.e. y=f(sum()) It adds non-linearity to a neural network, enabling it to learn complex patterns\n",
    "  examples of activation function are sigmoid tanh relu etc\n",
    "6.ouput has to be binary\n",
    "\n",
    "\n",
    "How it learns: \n",
    "1. weights and bias are initialized (usually to 0 or small random numbers)\n",
    "2. For a given input x, compute y\n",
    "3. If prediction is wrong, update weights using:\n",
    "\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a7cea127",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>CGPA</th>\n",
       "      <th>SGPA</th>\n",
       "      <th>Placed</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>9.1</td>\n",
       "      <td>9.3</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>7.5</td>\n",
       "      <td>7.2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>8.3</td>\n",
       "      <td>8.5</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>6.8</td>\n",
       "      <td>6.7</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>7.9</td>\n",
       "      <td>8.1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>9.0</td>\n",
       "      <td>9.4</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>6.2</td>\n",
       "      <td>6.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>8.6</td>\n",
       "      <td>8.7</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>7.2</td>\n",
       "      <td>7.1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>5.9</td>\n",
       "      <td>5.8</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>8.9</td>\n",
       "      <td>9.1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>9.2</td>\n",
       "      <td>9.5</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>6.5</td>\n",
       "      <td>6.3</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>7.8</td>\n",
       "      <td>7.9</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>7.0</td>\n",
       "      <td>6.8</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>8.1</td>\n",
       "      <td>8.3</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>9.5</td>\n",
       "      <td>9.6</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>6.7</td>\n",
       "      <td>6.6</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>8.0</td>\n",
       "      <td>8.2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>5.5</td>\n",
       "      <td>5.2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    CGPA  SGPA  Placed\n",
       "0    9.1   9.3       1\n",
       "1    7.5   7.2       0\n",
       "2    8.3   8.5       1\n",
       "3    6.8   6.7       0\n",
       "4    7.9   8.1       1\n",
       "5    9.0   9.4       1\n",
       "6    6.2   6.0       0\n",
       "7    8.6   8.7       1\n",
       "8    7.2   7.1       0\n",
       "9    5.9   5.8       0\n",
       "10   8.9   9.1       1\n",
       "11   9.2   9.5       1\n",
       "12   6.5   6.3       0\n",
       "13   7.8   7.9       1\n",
       "14   7.0   6.8       0\n",
       "15   8.1   8.3       1\n",
       "16   9.5   9.6       1\n",
       "17   6.7   6.6       0\n",
       "18   8.0   8.2       1\n",
       "19   5.5   5.2       0"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Perceptron\n",
    "\n",
    "data = {\n",
    "    'CGPA': [9.1, 7.5, 8.3, 6.8, 7.9, 9.0, 6.2, 8.6, 7.2, 5.9,\n",
    "             8.9, 9.2, 6.5, 7.8, 7.0, 8.1, 9.5, 6.7, 8.0, 5.5],\n",
    "    'SGPA': [9.3, 7.2, 8.5, 6.7, 8.1, 9.4, 6.0, 8.7, 7.1, 5.8,\n",
    "             9.1, 9.5, 6.3, 7.9, 6.8, 8.3, 9.6, 6.6, 8.2, 5.2],\n",
    "    'Placed': ['Yes', 'No', 'Yes', 'No', 'Yes', 'Yes', 'No', 'Yes', 'No', 'No',\n",
    "               'Yes', 'Yes', 'No', 'Yes', 'No', 'Yes', 'Yes', 'No', 'Yes', 'No']\n",
    "}\n",
    "\n",
    "df=pd.DataFrame(data)\n",
    "\n",
    "d={'Yes':1,'No':0}\n",
    "df['Placed']=df['Placed'].map(d)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "cb5fe046",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Yes\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "\n",
    "X = df[['CGPA', 'SGPA']]  # Features\n",
    "y = df['Placed']          # Target\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "from sklearn.linear_model import Perceptron\n",
    "\n",
    "model = Perceptron(max_iter=1000, eta0=0.1, random_state=42)\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "for key,val in d.items():\n",
    "    if model.predict(pd.DataFrame({'CGPA':[8.5],'SGPA':[8.2]}))[0] ==val:\n",
    "        print(key)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1356d7d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "#multi layered perceptron (ANN)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f238fc11",
   "metadata": {},
   "source": [
    "![Alt text](7.images\\ANN.png)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3384332",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "# Multi-Layered Perceptron (MLP) - Detailed Explanation\n",
    "\n",
    "# 1. Definition:\n",
    "# Multi-Layered Perceptron (MLP) is an Artificial Neural Network (ANN) consisting of multiple layers of neurons (also called perceptrons).\n",
    "# It is designed to model complex, non-linear relationships in data by learning hierarchical feature representations.\n",
    "\n",
    "# 2. Extension of Single-Layer Perceptron:\n",
    "# Unlike a single-layer perceptron which can only solve linearly separable problems,\n",
    "# MLP overcomes this limitation by adding one or more hidden layers and using non-linear activation functions.\n",
    "# This allows it to learn and approximate non-linear decision boundaries.\n",
    "\n",
    "# 3. Linear vs Non-linear Separability:\n",
    "# - Linear separability means classes can be separated by a single straight line (or hyperplane in higher dimensions) without error.\n",
    "# - If such a hyperplane exists, data is linearly separable.\n",
    "# - Otherwise, data is non-linearly separable, requiring more complex models like MLP.\n",
    "\n",
    "# 4. Architecture of MLP:\n",
    "# - Input Layer:\n",
    "#   Accepts raw input features (x1, x2, x3, ..., xn). \n",
    "#   This layer only passes inputs forward and does not perform computations.\n",
    "#\n",
    "# - Hidden Layer(s):\n",
    "#   One or more layers between input and output layers.\n",
    "#   Each neuron in these layers:\n",
    "#     * Receives inputs weighted by learned weights.\n",
    "#     * Adds a bias term.\n",
    "#     * Applies a non-linear activation function (e.g., ReLU, sigmoid, tanh).\n",
    "#   Hidden layers transform input features into intermediate representations, Intermediate representations are the new features or \n",
    "#                                                                             abstractions that the network creates inside the hidden\n",
    "#                                                                             layers by transforming raw input features through learned\n",
    "#                                                                             weights, biases, and nonlinear activations.\n",
    "#   enabling the network to learn non-linear and hierarchical patterns in data.\n",
    "\n",
    "# - Output Layer:\n",
    "#   Receives activations from the last hidden layer.\n",
    "#   Combines them linearly (weighted sum + bias).\n",
    "#   Applies an activation function suitable for the task (e.g., sigmoid for binary classification, softmax for multi-class).\n",
    "#   Produces the final output/prediction.\n",
    "\n",
    "# 5. Computation Flow (Forward Propagation):\n",
    "# For each layer l:\n",
    "#   z^(l) = W^(l) * a^(l-1) + b^(l)    # Linear transformation\n",
    "#   a^(l) = f(z^(l))                   # Non-linear activation function\n",
    "# where:\n",
    "#   - W^(l) is the weight matrix of layer l\n",
    "#   - b^(l) is the bias vector of layer l\n",
    "#   - a^(l-1) is the activation from previous layer (input features for l=1)\n",
    "#   - f(.) is the activation function (e.g., ReLU, sigmoid)\n",
    "\n",
    "# 6. Training:\n",
    "# MLPs are trained using supervised learning.\n",
    "# - A loss function (e.g., cross-entropy, mean squared error) measures prediction error.\n",
    "# - Backpropagation computes gradients of loss w.r.t weights and biases using chain rule.\n",
    "# - Optimizers (e.g., gradient descent, Adam) update parameters to minimize loss.\n",
    "\n",
    "# 7. Importance of Hidden Layers:\n",
    "# - Introduce non-linearity to the model.\n",
    "# - Extract and learn useful intermediate features.\n",
    "# - Enable learning of complex patterns beyond linear decision boundaries.\n",
    "# - Facilitate hierarchical feature abstraction (simple features combined into complex ones).\n",
    "\n",
    "# 8. Summary:\n",
    "# MLPs are powerful universal function approximators capable of modeling any continuous function given sufficient hidden units and data.\n",
    "# They form the basis of deep learning when stacked into many layers.\n",
    "\n",
    "\"\"\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "fcf9fca1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [20/100], Loss: 0.7768\n",
      "Epoch [40/100], Loss: 0.6019\n",
      "Epoch [60/100], Loss: 0.4525\n",
      "Epoch [80/100], Loss: 0.3176\n",
      "Epoch [100/100], Loss: 0.2221\n",
      "\n",
      "Test Accuracy: 93.33%\n",
      "\n",
      "Intermediate Representations (Hidden layer activations) for test samples:\n",
      "[[3.7363749  1.8109498  2.4422274  1.6650616  0.        ]\n",
      " [2.0104938  0.28940052 0.55733836 0.8819067  0.        ]\n",
      " [2.6664417  0.7620626  1.1081314  1.109611   0.        ]\n",
      " [1.161186   0.31915683 0.41723835 0.9242025  0.        ]\n",
      " [2.1518424  1.0848136  1.0675782  1.2661293  0.        ]\n",
      " [3.0458632  2.5037713  2.3608027  2.021271   0.        ]\n",
      " [3.0107298  0.32392246 0.5312183  0.9194027  0.        ]\n",
      " [2.2813072  0.         0.01360255 0.6162778  0.        ]\n",
      " [0.         0.         0.         0.         0.        ]\n",
      " [2.9028175  2.0751238  2.0483236  1.9226776  0.        ]\n",
      " [0.         0.         0.         0.         0.        ]\n",
      " [0.         0.         0.         0.         0.        ]\n",
      " [4.320433   1.9523396  2.4099846  1.7166615  0.        ]\n",
      " [2.6325233  1.3572593  1.5560156  1.3907108  0.        ]\n",
      " [0.         0.         0.         0.         0.        ]\n",
      " [1.6892914  1.9405627  1.545278   1.6394259  0.        ]\n",
      " [1.8056941  0.         0.         0.3761838  0.        ]\n",
      " [0.         0.         0.         0.         0.        ]\n",
      " [0.         0.         0.         0.         0.        ]\n",
      " [0.         0.         0.         0.         0.        ]\n",
      " [1.8391682  0.         0.25563347 0.7693831  0.        ]\n",
      " [0.         0.         0.         0.         0.        ]\n",
      " [1.9358926  0.05788225 0.48782486 0.9125979  0.        ]\n",
      " [3.1001415  2.290187   2.2413588  1.8345513  0.        ]\n",
      " [2.05005    1.0395737  0.9720454  1.2384269  0.        ]\n",
      " [1.3528862  0.12001389 0.34379017 0.878183   0.        ]\n",
      " [1.2815524  0.30859083 0.16389692 0.77548414 0.        ]\n",
      " [2.1602437  0.         0.         0.44973207 0.        ]\n",
      " [1.4116247  0.30758405 0.24865556 0.81711674 0.        ]\n",
      " [0.         0.         0.         0.         0.        ]\n",
      " [3.2098398  0.97640437 1.401569   1.1020772  0.        ]\n",
      " [3.5406208  2.3827467  2.3365731  1.905427   0.        ]\n",
      " [0.60305166 0.13740903 0.06184345 0.7952495  0.        ]\n",
      " [0.         0.         0.         0.         0.        ]\n",
      " [3.451854   1.740515   1.9046508  1.6201138  0.        ]\n",
      " [0.         0.         0.         0.         0.        ]\n",
      " [0.         0.         0.         0.         0.        ]\n",
      " [0.         0.         0.         0.         0.        ]\n",
      " [0.         0.         0.         0.         0.        ]\n",
      " [2.4894776  0.9286118  1.2435368  1.2921174  0.        ]\n",
      " [1.8770134  0.09277463 0.27199352 0.7318058  0.        ]\n",
      " [0.         0.         0.         0.         0.        ]\n",
      " [2.5826159  1.1678143  0.82469213 1.1466539  0.        ]\n",
      " [2.70093    1.6178784  1.6594974  1.5816438  0.        ]\n",
      " [2.209581   0.04221582 0.58461094 0.8733064  0.        ]]\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from sklearn.datasets import load_iris\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import accuracy_score\n",
    "import numpy as np\n",
    "\n",
    "# 1. Load and preprocess the Iris dataset\n",
    "iris = load_iris()\n",
    "X = iris.data       # shape (150,4)\n",
    "y = iris.target     # shape (150,)\n",
    "\n",
    "# Scale features for better training\n",
    "scaler = StandardScaler()\n",
    "X_scaled = scaler.fit_transform(X)\n",
    "\n",
    "# Convert to tensors A tensor is a multi-dimensional array\n",
    "X_tensor = torch.tensor(X_scaled, dtype=torch.float32)\n",
    "y_tensor = torch.tensor(y, dtype=torch.long)\n",
    "\n",
    "# Train-test split\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X_tensor, y_tensor, test_size=0.3, random_state=42, stratify=y_tensor\n",
    ")\n",
    "\n",
    "# 2. Define a simple MLP with one hidden layer\n",
    "class SimpleMLP(nn.Module):\n",
    "    def __init__(self, input_dim=4, hidden_dim=5, output_dim=3):\n",
    "        super(SimpleMLP, self).__init__()\n",
    "        self.hidden = nn.Linear(input_dim, hidden_dim)\n",
    "        self.activation = nn.ReLU()\n",
    "        self.output = nn.Linear(hidden_dim, output_dim)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        # Forward pass with intermediate representation extraction\n",
    "        z1 = self.hidden(x)          # Linear transform (hidden layer)\n",
    "        a1 = self.activation(z1)     # Hidden layer activations (intermediate representation)\n",
    "        out = self.output(a1)        # Output layer (logits)\n",
    "        return out, a1               # Return both final output and intermediate reps\n",
    "\n",
    "# Instantiate model\n",
    "model = SimpleMLP()\n",
    "\n",
    "# Loss and optimizer\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.01)\n",
    "\n",
    "# 3. Training loop\n",
    "epochs = 100\n",
    "for epoch in range(epochs):\n",
    "    model.train()\n",
    "    \n",
    "    optimizer.zero_grad()\n",
    "    outputs, _ = model(X_train)\n",
    "    loss = criterion(outputs, y_train)\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    \n",
    "    if (epoch + 1) % 20 == 0:\n",
    "        print(f\"Epoch [{epoch+1}/{epochs}], Loss: {loss.item():.4f}\")\n",
    "\n",
    "# 4. Evaluate on test data and print accuracy\n",
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    outputs, intermediate_activations = model(X_test)\n",
    "    _, predicted = torch.max(outputs, 1)\n",
    "    acc = accuracy_score(y_test, predicted)\n",
    "    print(f\"\\nTest Accuracy: {acc*100:.2f}%\")\n",
    "\n",
    "# 5. Visualize some intermediate representations for test samples\n",
    "print(\"\\nIntermediate Representations (Hidden layer activations) for test samples:\")\n",
    "print(intermediate_activations.numpy())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a024486c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#convolutional neural network "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8cb7a16",
   "metadata": {},
   "source": [
    "![Alt text](7.images\\CNN.webp)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f48a19e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "A **Convolutional Neural Network (CNN)** is a type of deep learning model specifically designed for **processing data with grid-like topology**, such as **images** (2D grids of pixels) or **audio spectrograms** (1D or 2D). CNNs are a subclass of **Artificial Neural Networks (ANNs)** that are particularly effective for **visual tasks**‚Äîclassification, detection, segmentation, etc.\n",
    "\n",
    "---\n",
    "\n",
    "## üîç Why Use CNNs?\n",
    "\n",
    "Traditional ANNs **struggle with high-dimensional inputs** like images. For example, a 256√ó256 RGB image has 256√ó256√ó3 = **196,608 input features**. Fully connecting all neurons would result in **huge computation and overfitting**.\n",
    "\n",
    "CNNs **reduce the number of parameters**, capture **spatial features**, and provide **translation invariance** using three core concepts:\n",
    "\n",
    "1. **Local connectivity**\n",
    "2. **Parameter sharing**\n",
    "3. **Downsampling (pooling)**\n",
    "\n",
    "---\n",
    "\n",
    "## üß± CNN Architecture Components (Layer by Layer)\n",
    "\n",
    "### 1. **Input Layer**\n",
    "\n",
    "* Accepts the raw image (e.g., 28√ó28 grayscale image ‚Üí shape = 28√ó28√ó1)\n",
    "\n",
    "---\n",
    "\n",
    "### 2. **Convolutional Layer (`Conv2D`)**\n",
    "\n",
    "* **Purpose**: Detect **features** like edges, corners, textures, shapes, etc.\n",
    "* **How it works**: Uses small filters (kernels), e.g., 3√ó3, that **slide over** the input image and perform **element-wise multiplication and summation**.\n",
    "\n",
    "üìå **Mathematically:**\n",
    "\n",
    "$$\n",
    "\\text{Feature map} = \\text{Input} * \\text{Kernel}\n",
    "$$\n",
    "\n",
    "* Each kernel produces **one feature map**\n",
    "* **Parameters** in kernels are learned during training\n",
    "\n",
    "#### üîë Hyperparameters:\n",
    "\n",
    "* **Number of filters** (feature detectors)\n",
    "* **Kernel size** (e.g., 3√ó3, 5√ó5)\n",
    "* **Stride** (how many pixels to move the filter each step)\n",
    "* **Padding** (zero-padding to retain dimensions)\n",
    "\n",
    "---\n",
    "\n",
    "### 3. **Activation Layer (ReLU)**\n",
    "\n",
    "* Applies **non-linearity** to feature maps\n",
    "\n",
    "üìå **Why?** CNN without non-linearity becomes just a linear model.\n",
    "\n",
    "* Most common: **ReLU (Rectified Linear Unit)**\n",
    "\n",
    "  $$\n",
    "  \\text{ReLU}(x) = \\max(0, x)\n",
    "  $$\n",
    "\n",
    "---\n",
    "\n",
    "### 4. **Pooling Layer (`MaxPooling2D`)**\n",
    "\n",
    "* **Purpose**: Downsample the spatial dimension ‚Üí reduce computation and overfitting\n",
    "\n",
    "üìå Types:\n",
    "\n",
    "* **Max pooling**: selects maximum value in a patch\n",
    "* **Average pooling**: takes average\n",
    "\n",
    "E.g., a 2√ó2 max pool reduces 4 values to 1.\n",
    "\n",
    "---\n",
    "\n",
    "### 5. **Flatten Layer**\n",
    "\n",
    "* Converts the final pooled 2D feature maps into a **1D vector** for the dense layers.\n",
    "\n",
    "---\n",
    "\n",
    "### 6. **Fully Connected Layer (Dense Layer)**\n",
    "\n",
    "* Traditional neural network layer\n",
    "* Learns to map the extracted features to class scores.\n",
    "\n",
    "E.g., last Dense layer might have `n` neurons for `n` classes with a **Softmax** activation for classification.\n",
    "\n",
    "---\n",
    "\n",
    "### 7. **Output Layer**\n",
    "\n",
    "* Depends on the task:\n",
    "\n",
    "  * **Binary classification**: 1 neuron with `sigmoid`\n",
    "  * **Multi-class classification**: `n` neurons with `softmax`\n",
    "  * **Regression**: linear activation\n",
    "\n",
    "---\n",
    "\n",
    "## üß† Summary of Data Flow\n",
    "\n",
    "```\n",
    "Image ‚Üí Conv ‚Üí ReLU ‚Üí Pool ‚Üí Conv ‚Üí ReLU ‚Üí Pool ‚Üí Flatten ‚Üí Dense ‚Üí Output\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "## üñºÔ∏è Visual Example (Simplified)\n",
    "\n",
    "```\n",
    "Input Image (28√ó28√ó1)\n",
    "   ‚Üì\n",
    "Conv Layer (3√ó3√ó32 filters) ‚Üí Output: 26√ó26√ó32\n",
    "   ‚Üì\n",
    "ReLU\n",
    "   ‚Üì\n",
    "MaxPooling (2√ó2) ‚Üí Output: 13√ó13√ó32\n",
    "   ‚Üì\n",
    "Conv Layer (3√ó3√ó64) ‚Üí Output: 11√ó11√ó64\n",
    "   ‚Üì\n",
    "ReLU\n",
    "   ‚Üì\n",
    "MaxPooling (2√ó2) ‚Üí Output: 5√ó5√ó64\n",
    "   ‚Üì\n",
    "Flatten ‚Üí 1600 units\n",
    "   ‚Üì\n",
    "Dense (128)\n",
    "   ‚Üì\n",
    "Dense (10) ‚Üí Softmax (for classification into 10 classes)\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "## üß† Key Benefits of CNNs\n",
    "\n",
    "| Feature                    | Benefit                                                             |\n",
    "| -------------------------- | ------------------------------------------------------------------- |\n",
    "| **Local receptive fields** | Neurons focus on small regions, making it computationally efficient |\n",
    "| **Weight sharing**         | Fewer parameters than fully connected layers                        |\n",
    "| **Translation invariance** | Ability to detect features anywhere in the image                    |\n",
    "| **Compositionality**       | Early layers detect edges, later layers detect shapes or objects    |\n",
    "\n",
    "---\n",
    "\n",
    "## üß™ CNN in PyTorch (Simple Example)\n",
    "\n",
    "```python\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "class CNN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(CNN, self).__init__()\n",
    "        # Conv layer 1: in_channels=1, out_channels=32, kernel=3\n",
    "        self.conv1 = nn.Conv2d(1, 32, 3)\n",
    "        self.pool = nn.MaxPool2d(2, 2)\n",
    "        self.conv2 = nn.Conv2d(32, 64, 3)\n",
    "        self.fc1 = nn.Linear(64 * 5 * 5, 128)\n",
    "        self.fc2 = nn.Linear(128, 10)  # For 10 classes\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.pool(F.relu(self.conv1(x)))  # Conv1 + ReLU + Pool\n",
    "        x = self.pool(F.relu(self.conv2(x)))  # Conv2 + ReLU + Pool\n",
    "        x = x.view(-1, 64 * 5 * 5)            # Flatten\n",
    "        x = F.relu(self.fc1(x))               # FC1\n",
    "        x = self.fc2(x)                       # Output layer\n",
    "        return x\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "## üì¶ Applications of CNNs\n",
    "\n",
    "| Domain                | Example                                   |\n",
    "| --------------------- | ----------------------------------------- |\n",
    "| **Computer Vision**   | Image classification (e.g., MNIST, CIFAR) |\n",
    "| **Medical Imaging**   | Tumor detection, X-ray analysis           |\n",
    "| **Self-driving Cars** | Object and lane detection                 |\n",
    "| **Face Recognition**  | Feature extraction and classification     |\n",
    "| **Document Analysis** | OCR (Optical Character Recognition)       |\n",
    "\n",
    "---\n",
    "\n",
    "## üöß Limitations\n",
    "\n",
    "* Not rotationally or scale invariant by default\n",
    "* Still needs large amounts of labeled data\n",
    "* Struggles with very complex contextual understanding (better handled with transformers today)\n",
    "\n",
    "---\n",
    "\n",
    "Want to implement a working CNN on a real dataset like MNIST or CIFAR-10? Let me know and I‚Äôll give you a full working code walkthrough in PyTorch or TensorFlow.\n",
    "\n",
    "\"\"\""
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
