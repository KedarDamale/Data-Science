{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e27a3e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Unsupervised Learning is a type of machine learning where:\n",
    "\n",
    "The model is trained on unlabeled data i.e only input features (x) no y is provided.\n",
    "\n",
    "It tries to find hidden patterns, structures, or distributions in the input data.\n",
    "\n",
    "The output is not explicitly provided, unlike supervised learning.\n",
    "\n",
    "Major typesd of unsupervide learning: 1.Clustering \n",
    "\n",
    "                                      {\n",
    "                                          Clustering is an unsupervised machine learning \n",
    "                                          technique used to group similar data points together\n",
    "                                          based on intrinsic patterns or similarities in the \n",
    "                                          data, without the use of labeled outcomes. It is \n",
    "                                          one of the core tasks in exploratory data mining,\n",
    "                                          where the goal is to uncover natural groupings in datasets.\n",
    "                                          \n",
    "                                          Clustering aims to divide a set of data points into K groups (clusters) such that:\n",
    "\n",
    "                                                Intra-cluster similarity is high (points in the same cluster are similar)\n",
    "                                                Inter-cluster similarity is low (points in different clusters are dissimilar)\n",
    "\n",
    "                                          Types of clustering: 1.Partition-based Clustering: Divides the data into K clusters \n",
    "                                                                                            based on minimizing intra-cluster \n",
    "                                                                                            variance (or distance). Centroid\n",
    "                                                                                            represents the mean of points in \n",
    "                                                                                            the cluster.Example: K-Means\n",
    "                                                                2.Hierarchical Clustering: Types: Agglomerative (bottom-up): Start with individual points, merge closest pair iteratively\n",
    "                                                                                                  Divisive (top-down): Start with one big cluster, split recursively\n",
    "                                                                                            Example: AGNES and DIANA\n",
    "                                                                3.Density-based Clustering: Forms clusters based on dense regions of points separated by low-density areas.Example DBSCAN\n",
    "                                      }\n",
    "                                      2. Association rule analysis: Association Rule Mining (ARM)\n",
    "                                                                    is a fundamental concept in \n",
    "                                                                    unsupervised learning and data mining, \n",
    "                                                                    primarily used to discover interesting relationships,\n",
    "                                                                    patterns, or correlations among a set of items in large datasets.\n",
    "                                                                    \n",
    "                                                                    Terminologies: 1.Itemset: A collection of one or more items.\n",
    "                                                                                              E.g {milk,bread,butter,milk,fruits,butter} is a 6-itemset\n",
    "                                                                                   2.Suppport: Frequency (proportion) of transactions that contain an itemset.\n",
    "                                                                                               support(milk)=number of milk in set/total item number=2/6\n",
    "                                                                                   3.Confidence:likeligood of b happening when a has happend\n",
    "                                                                                                lets say these are itemsets {milk,butter} {milk,bread},{bread,butter}\n",
    "                                                                                                \n",
    "                                                                                                conf(milk->butter)=a nad b both occuring/support of a\n",
    "                                                                                                          = 1/(2/3)  supoort of milk is 2/3 becuse milk is in 2 out of 3 transaction\n",
    "                                                                                                          \n",
    "                                                                                                conf(butter->milk)=1/support of butter\n",
    "                                                                                                                  =1/(2/3)  #these two can be differenct\n",
    "                                                                                    4.lift :Measures how much more likely B \n",
    "                                                                                            has happened when A has happened, \n",
    "                                                                                            compared to B happening independently.\n",
    "                                                                                            lift(milk->butter)= conf(milk->butter)/support(butter)\n",
    "                                                                                                              =3/2 * (2/3)\n",
    "                                         Eg. Apriori,Fp growth tree\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "\"\"\"\n",
    "🔵 What is a Cluster?\n",
    "A cluster is a collection of data points grouped together because of similarity or proximity based on some defined distance metric (e.g., Euclidean). \n",
    "The goal of clustering is to discover natural groupings in the data.\n",
    "\n",
    "1. Cluster Centroid:The central point of a cluster (mean of all the data points in that cluster).\n",
    "(80,85),(82,88),(78,84),\n",
    "then centroid = mean = (80,85.67) \n",
    "\n",
    "2.Inter cluster distance: Inter-cluster distance measures how far apart two clusters are. It’s used to evaluate the separation between clusters.\n",
    "\n",
    "Types of distance measurements:\n",
    "| Type                  | Definition                                                             | Used in       |\n",
    "| --------------------- | ---------------------------------------------------------------------- | ------------- |\n",
    "| **Single Linkage**    | Minimum distance between any two points (one from each cluster)        | Hierarchical  |\n",
    "| **Complete Linkage**  | Maximum distance between any two points (one from each cluster)        | Hierarchical  |\n",
    "| **Average Linkage**   | Average of all pairwise distances between the clusters                 | Hierarchical  |\n",
    "| **Centroid Distance** | Euclidean distance between the centroids of two clusters               | K-Means, etc. |\n",
    "| **Ward’s Distance**   | Increase in total within-cluster variance when two clusters are merged | Ward's method |\n",
    "\n",
    "3.ilhouette Score: Measures how similar a point is to its own cluster (cohesion) vs other clusters (separation).\n",
    "\n",
    "s=b-a/max(a,b) a: average intra-cluster distance b: average nearest-cluster distance\n",
    "\n",
    "4.Similarity and disssimilarity measurement technics: euclidian distance, mahatten distance and cosine similarity \n",
    "\n",
    "cosine similarity=A.B/||A|| ||B||\n",
    "A>B is dot product size of a = sum(root(Ai^2))\n",
    "\n",
    "# Vectors\n",
    "A = np.array([1, 2, 3])\n",
    "B = np.array([4, 5, 6])\n",
    "\n",
    "# ----------------------------------------------------------\n",
    "# Step 1: Dot Product\n",
    "# A · B = (1*4) + (2*5) + (3*6) = 4 + 10 + 18 = 32\n",
    "# ----------------------------------------------------------\n",
    "dot_product = np.dot(A, B)\n",
    "\n",
    "# ----------------------------------------------------------\n",
    "# Step 2: Magnitude (Euclidean norm)\n",
    "# ||A|| = sqrt(1^2 + 2^2 + 3^2) = sqrt(14)\n",
    "# ||B|| = sqrt(4^2 + 5^2 + 6^2) = sqrt(77)\n",
    "# ----------------------------------------------------------\n",
    "magnitude_A = np.linalg.norm(A)  # sqrt(1^2 + 2^2 + 3^2) = sqrt(14)\n",
    "magnitude_B = np.linalg.norm(B)  # sqrt(4^2 + 5^2 + 6^2) = sqrt(77)\n",
    "\n",
    "# ----------------------------------------------------------\n",
    "# Step 3: Cosine Similarity\n",
    "# cosine(θ) = (A · B) / (||A|| * ||B||)\n",
    "#            = 32 / (sqrt(14) * sqrt(77)) ≈ 0.9746\n",
    "# ----------------------------------------------------------\n",
    "cosine_similarity = dot_product / (magnitude_A * magnitude_B)\n",
    "\n",
    "\n",
    "5.Types of clustering\n",
    "\n",
    "| Type            | Meaning                                                   | Example                       |\n",
    "| --------------- | --------------------------------------------------------- | ----------------------------- |\n",
    "| Hard Clustering | Each point belongs to exactly one cluster                 | K-Means                       |\n",
    "| Soft Clustering | Each point has a probability of belonging to each cluster | Gaussian Mixture Models (GMM) |\n",
    "\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd6e5eca",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "K mean clustering\n",
    "\n",
    "it takes unlabelled dataset means only inoput feature no output features\n",
    "\n",
    "k in k means stands for number of clusters that will be formed , it has to be give by user\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61681a77",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03fbb2ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Apriori Alogrithm\n",
    "\n",
    "\"\"\"\n",
    "Market Basket Analysis (MBA) is a data mining technique used by retailers to discover patterns in customer purchase behavior. It identifies combinations of products that frequently co-occur in transactions.\n",
    "\n",
    "Think of it like: “If a customer buys bread, how likely are they to also buy butter or jam in the same basket?”\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "data = [\n",
    "    ['Milk', 'Bread', 'Butter'],\n",
    "    ['Bread', 'Butter'],\n",
    "    ['Milk', 'Bread'],\n",
    "    ['Milk', 'Butter'],\n",
    "    ['Bread'],\n",
    "    ['Milk', 'Bread', 'Butter', 'Eggs'],\n",
    "    ['Bread', 'Eggs'],\n",
    "    ['Milk', 'Eggs'],\n",
    "    ['Milk', 'Bread', 'Eggs'],\n",
    "    ['Butter', 'Eggs']\n",
    "]\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
